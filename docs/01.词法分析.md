# 1.词法分析

## 1.1 词法分析概述

词法分析实际上的作用是将原本并无意义的字符串（我们的输入）转化为词素，生成并输出一个个词法单元。

不仅仅是一门语言需要用到词法分析，实际上我们在更多地方都能看见它，比如我们的数据库，SQL语句其实也是一个个的词素的组合，
还有其他可交互平台中，我们在Shell中的输入，实际上也同样会被转化为对应的词法单元，然后再通过语法分析，最后再交由机器执行。

所以词法分析其实就相当于我们阅读文言文的时候，是不是会对大部分的词语进行标注，从而才能为接下来翻译的过程做好准备。

## 1.2 词法单元

所以让我们先来畅想一下BY-Monkey语言吧。

```
let age = 1;
let b = 1 - 1 + 1 * 1 + 1 / 1;

let t = true;
let name = "BY-Monkey";

let myArray = [1, 2, 3, 4];
let BY = {"name":"炳源","age":21};

puts(age);
puts(t);
puts(name);

puts(myArray[0]);
puts(BY["name"])

let newAdder = fn(x) { fn(y){x + y} };
let addTwo = newAdder(2);

addTwo(3);
```

上述代码中，我们能够大体把遇到的词法单元分为以下几类：

- 操作符：`+,-,*,/,=`
- 标识符，也就是我们的变量名和函数名，我们把他们归为一类
- 关键字：`let,fn`
- 内置函数：`puts`上述例子中只展示了这一个内置函数，不过没事，我们会逐步添加的！
- 特殊字符：`(,),[,],{,},:,EOF`
- 字面量：字面量即`1234`,`"1234"`,`ture`这类数值or字符串，他们也是我们词法单元的一类

确立了我们需要的词法单元，下一步就是编写对应的`token`文件。

这玩意有点像我们的词典，但是不是给我们读的，而是要交给下一个步骤要实现的模块——词法分析器来读的。

`./token/token.go`
```
package token

type TokenType string

const (
	ILLEGAL = "ILLEGAL"
	EOF     = "EOF"

	PLUS     = "+"
	MINUS    = "-"
	ASTERISK = "*"
	SLASH    = "/"


	LPAREN   = "("
	RPAREN   = ")"
	LBRACE   = "{"
	RBRACE   = "}"
	LBRACKET = "["
	RBRACKET = "]"

)

type Token struct {
	Type    TokenType
	Literal string
}
```

上述的`Token`就是我们的词法单元，并将每个基础的符号先做了标记，先不必着急其他的标识符关键字，我们先从它来上手，
了解词法分析器的机制，我们就能很快扩展出我们的各个词法单元了。

大体上确立了我们的 *词典* ，接下来就要来编写我们真正的解释器的第一个模块了。

## 1.3 词法分析器

词法分析器实际上就相当于一个能够自动帮我们把词典上的注释搬到原本的书本——也就是源代码的一个功能。

经过了这个步骤，我们至少能把原本都看似无规则的语句划分称为一个个的单元，并且能知道这个单元表示的是什么。

我们先来定义一下基础的词法分析器结构：

`./lexer/lexer.go`

```
type Lexer struct {
	input        string
	position     int  // 所输入字符串中的当前位置
	readPosition int  // 所输入字符串中的当前读取位置
	ch           byte // 当前正在读取的字符
}

func New(input string) *Lexer {
	l := &Lexer{input: input}
	l.readChar()
	return l
}

func (l *Lexer) readChar() {
	if l.readPosition >= len(l.input) {
		l.ch = 0
	} else {
		l.ch = l.input[l.readPosition]
	}
	l.position = l.readPosition
	l.readPosition += 1
}
```

虽然注释已经写了，但是还是再解释一遍，首先`input`是我们正在处理的整段代码，`position`则是我们正在分析的位置，
`readPosition`则是一个类似于缓冲区的位置，是我们已经读取但是还没有分析的位置，我们可以通过这个来实现“偷窥”下一个字符的功能，
从而能够更好地判断当前的词法单元是什么。

有了基础结构显然也是不够的，我们还需要准备将这个词法分析器初始化的函数，以及“阅读原文”的对应函数，才能够使这个词法分析器具有能跑起来的能力。

这里我们的`New()`方法和`readChar()`则分别对应着初始化和阅读。

这就是我们伟大的词法分析器的入口了！

但是它现在的能力还不足以识别词法单元。我们还需要对其进行完善，我们继续来编写一个`nextToken()`函数，这个函数能够返回当前正在阅读的词法单元。

我们还是从比较简单的情况开始吧。首先我们来尝试识别一下括号和加减乘除。

`./lexer/lexer.go`
```
func (l *Lexer) skipWhitespace() {
	for l.ch == ' ' || l.ch == '\t' || l.ch == '\n' || l.ch == '\r' {
		l.readChar()
	}
}

func (l *Lexer) NextToken() token.Token {
	var tok token.Token
	
	l.skipWhitespace()
	
	switch l.ch {
	case '+':
		tok = newToken(token.PLUS, l.ch)
	case '-':
		tok = newToken(token.MINUS, l.ch)
	case '/':
		tok = newToken(token.SLASH, l.ch)
	case '*':
		tok = newToken(token.ASTERISK, l.ch)
	case '(':
		tok = newToken(token.LPAREN, l.ch)
	case ')':
		tok = newToken(token.RPAREN, l.ch)
	case '{':
		tok = newToken(token.LBRACE, l.ch)
	case '}':
		tok = newToken(token.RBRACE, l.ch)
	case '[':
		tok = newToken(token.LBRACKET, l.ch)
	case ']':
		tok = newToken(token.RBRACKET, l.ch)
	case 0:
		tok.Literal = ""
		tok.Type = token.EOF
	
	l.readChar()
	return tok
}
```

首先是`skipWhitespace()`这个函数，我们稍微看一下便能明白其功能，就是将空格和换行等等我们并不需要的，为了让代码更具有可读性的部分跳过。

然后则是`NextToken()`，我们在这个函数中才真正实现了读取并加上“注释”的这一功能，其实这一宏大的功能这样子一看，并不是那么难以理解。

我们对于当前`lexer`正在解析的字符进行判断，并把不同种类的括号与运算符和他们对应的词法单元，然后返回对应的`Token`，便完成了标注。

好的，恭喜！我们已经实现了一个简陋的词法分析器（即便它只能分析括号和加减乘除），但是我们还是需要将对应的测试样例完善好（这也是我的比较不好的习惯？先写代码后写测试代码）


`./lexer/lexer_test.go`
```
package lexer

import (
	"Monkey/token"
	"testing"
)

func TestNextToken(t *testing.T) {
	input := `()[]{}`

	tests := []struct {
		expectedType    token.TokenType
		expectedLiteral string
	}{
		{token.LPAREN, "("},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.RBRACE, "}"},
		{token.LBRACKET, "["},
		{token.RBRACKET, "]"},
	}

	l := New(input)
	for i, tt := range tests {
		tok := l.NextToken()

		if tok.Type != tt.expectedType {
			t.Fatalf("tests[%d] - tokentype wrong. expected=%q, got=%q",
				i, tt.expectedType, tok.Type)
		}

		if tok.Literal != tt.expectedLiteral {
			t.Fatalf("tests[%d] - literal wrong. expected=%q, got=%q",
				i, tt.expectedLiteral, tok.Literal)
		}
	}
}

```

如预期一样，我们的测试通过了！
